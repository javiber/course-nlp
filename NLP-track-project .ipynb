{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP track project\n",
    "\n",
    "\n",
    "The goal of this project is to guide you through the latest techniques in NLP, we have chosen to frame that journey around the problem of *Machine Translation*, More specifically english-spanish translation. \n",
    "\n",
    "The motivation for centering around this particular problem is that it's a complex one that has been revolutionized lately. So It will guide you from the basics to the latest SOA techniques.\n",
    "\n",
    "The reason we choose English and Spanish is purely because we happen to know both of them, if you would like to explore other language feel free to do so but make sure you have a proper dataset that you can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline\n",
    "\n",
    "As a baseline we will first train a simple encoder-decoder architecture. The code is based on the [seq2seq notebook](https://github.com/fastai/course-nlp/blob/master/7-seq2seq-translation.ipynb) from the [lesson 12](https://www.youtube.com/watch?v=IfsjMg4fLWQ&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=13&t=0s) of the Fast.ai's NLP course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset\n",
    "\n",
    "The dataset we will use was build by [Open Subtitles](https://www.opensubtitles.org/) and consists of movie and series subtitles, we chose this dataset over the alternatives because it contains casual and more simple language than the alternatives (UN resolutions, EU parlament sessions, etc). You can look at the alternatives on this [amazing site](http://opus.nlpl.eu/).\n",
    "\n",
    "Unfurtunately the spanish used is from Spain, not sure why the Latin American version of the subtitles is not available.\n",
    "\n",
    "The dataset is extremely large and not in a great format, you can see how we processed it on [this notebook](./subtitles-download.ipynb). There is no need to run it, the resulting csv should be available in [???]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javiber/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('subtitles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7990657\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4683972</th>\n",
       "      <td>en/2013/2450744/4863403.xml#es/2013/2450744/48...</td>\n",
       "      <td>512</td>\n",
       "      <td>You 're Malcolm 's new hero .</td>\n",
       "      <td>Eres el nuevo héroe de Malcolm .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845013</th>\n",
       "      <td>en/2000/216800/215763.xml#es/2000/216800/57166...</td>\n",
       "      <td>685</td>\n",
       "      <td>Good ... and you ?</td>\n",
       "      <td>Bien , ¿ y a ti ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505119</th>\n",
       "      <td>en/2012/2555708/5582609.xml#es/2012/2555708/58...</td>\n",
       "      <td>141</td>\n",
       "      <td>Come on , now , is that a donut or what ?</td>\n",
       "      <td>Vamos , ahora , es ¿ Que una dona o qué ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570567</th>\n",
       "      <td>en/1990/99348/5628189.xml#es/1990/99348/400608...</td>\n",
       "      <td>278</td>\n",
       "      <td>It is for a girl .</td>\n",
       "      <td>Para una chica .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977199</th>\n",
       "      <td>en/2012/2174327/4499006.xml#es/2012/2174327/61...</td>\n",
       "      <td>196</td>\n",
       "      <td>So you 're watching him ?</td>\n",
       "      <td>¿ Entonces le estás vigilando ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     files sub_id  \\\n",
       "4683972  en/2013/2450744/4863403.xml#es/2013/2450744/48...    512   \n",
       "845013   en/2000/216800/215763.xml#es/2000/216800/57166...    685   \n",
       "4505119  en/2012/2555708/5582609.xml#es/2012/2555708/58...    141   \n",
       "570567   en/1990/99348/5628189.xml#es/1990/99348/400608...    278   \n",
       "3977199  en/2012/2174327/4499006.xml#es/2012/2174327/61...    196   \n",
       "\n",
       "                                                en  \\\n",
       "4683972              You 're Malcolm 's new hero .   \n",
       "845013                          Good ... and you ?   \n",
       "4505119  Come on , now , is that a donut or what ?   \n",
       "570567                          It is for a girl .   \n",
       "3977199                  So you 're watching him ?   \n",
       "\n",
       "                                                es  \n",
       "4683972           Eres el nuevo héroe de Malcolm .  \n",
       "845013                           Bien , ¿ y a ti ?  \n",
       "4505119  Vamos , ahora , es ¿ Que una dona o qué ?  \n",
       "570567                            Para una chica .  \n",
       "3977199            ¿ Entonces le estás vigilando ?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "files     0\n",
       "sub_id    0\n",
       "en        8\n",
       "es        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "files     0\n",
       "sub_id    0\n",
       "en        0\n",
       "es        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(50000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tokenization and Numericalization\n",
    "\n",
    "Unfurtunately the dataset was already tokenized, that's why you see spaces around punctuation marks. Not a big deal but we'd have rather the raw messages.\n",
    "\n",
    "Anyway for this baseline we will use the default settings from fast.ai which is to use spaCy's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Data collate\n",
    "\n",
    "In order to run the RNN in parallel for a whole batch, all examples in a batch must have the same size. \n",
    "To accomplish this we'll add padding where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x = max([len(s[0]) for s in samples])\n",
    "    max_len_y = max([len(s[1]) for s in samples])\n",
    "    \n",
    "    # create matrices of the target size we want (batch_lenght x max_sentence_lenght_in_batch) full of padding\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    \n",
    "    if backwards: \n",
    "        pad_first = not pad_first\n",
    "    \n",
    "    for i, s in enumerate(samples):\n",
    "        # replace the part of the correct part of the padded matrices with the actual values\n",
    "        if pad_first: \n",
    "            res_x[i, -len(s[0]):] = LongTensor(s[0])\n",
    "            res_y[i, -len(s[1]):] = LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):] = LongTensor(s[0])\n",
    "            res_y[i,:len(s[1]):] = LongTensor(s[1])\n",
    "            \n",
    "    if backwards: \n",
    "        res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    \n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Custom databunch\n",
    "\n",
    "On the training set, we don't want to mix really long senteces with really short because that'd create lots of padding, instead we'll use fast.ai's `SortishSampler` to keep the sentences of a batch relatively the same size while also having some randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create(\n",
    "            cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "           dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n",
    "            **dl_kwargs) -> DataBunch:\n",
    "        \"\"\"\n",
    "        Function that transform the `datasets` in a `DataBunch` for classification. \n",
    "        Passes `**dl_kwargs` on to `DataLoader()`\n",
    "        \"\"\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = bs if val_bs is None else val_bs \n",
    "        \n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        \n",
    "        # Sample data randomly but trying to keep the lenghts similar\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        \n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            \n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "            \n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
    "    \n",
    "    \n",
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.home()/'open_subtitles'\n",
    "\n",
    "src = (Seq2SeqTextList\n",
    "       .from_df(df, path=path, cols='en')\n",
    "       .split_by_rand_pct(seed=42)\n",
    "       .label_from_df(cols='es', label_cls=TextList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Analyze sentence length\n",
    "Some sentences are extremely large so we will remove those outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.0, 81)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lengths = [len(o) for o in src.train.x.items] + [len(o) for o in src.valid.x.items]\n",
    "np.percentile(x_lengths, 90), np.max(x_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.0, 65)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lengths = [len(o) for o in src.train.y.items] + [len(o) for o in src.valid.y.items]\n",
    "np.percentile(y_lengths, 90), np.max(y_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src.filter_by_func(lambda x,y: len(x) > 10 or len(y) > 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30112"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src.train) + len(src.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = src.databunch(bs=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj no , no , no , no !</td>\n",
       "      <td>xxbos xxmaj no , no , no , no !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos - xxmaj they 'll be at the xxunk .</td>\n",
       "      <td>xxbos - xxmaj estarán en el refugio .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj are you gon na dance or what ?</td>\n",
       "      <td>xxbos xxmaj vas a bailar o que ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i ' m happy to . xxmaj okay .</td>\n",
       "      <td>xxbos xxmaj estoy feliz de ayudar .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj ah , my fiancée princess xxmaj xxunk .</td>\n",
       "      <td>xxbos xxmaj ah , mi prometida la princesa xxmaj xxunk .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** how does fastai know which tokenizer to use? is it using english tokenizer on spanish?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Load saved databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.home()/'open_subtitles'\n",
    "data = load_data(path, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Embeddings\n",
    "\n",
    "We will use the embedings from [fastText](https://fasttext.cc/docs/en/support.html) because they have pretrained models that are good enough for our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Download pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz -P {path}\n",
    "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.bin.gz -P {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gunzip {path}/cc.en.300.bin.gz\n",
    "# ! gunzip {path}/cc.es.300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "es_vecs = ft.load_model(str((path/'cc.es.300.bin')))\n",
    "en_vecs = ft.load_model(str((path/'cc.en.300.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 missing words\n",
      "42 missing words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([5808, 300]), torch.Size([7016, 300]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_emb(vecs, itos, em_sz=300, mult=1.):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    vec_dic = {w: vecs.get_word_vector(w) for w in vecs.get_words()}\n",
    "    miss = 0\n",
    "    for i, w in enumerate(itos):\n",
    "        try: \n",
    "            wgts[i] = tensor(vec_dic[w])\n",
    "        except: \n",
    "            miss += 1\n",
    "    print(f'{miss} missing words')\n",
    "    return emb\n",
    "\n",
    "emb_enc = create_emb(en_vecs, data.x.vocab.itos)\n",
    "emb_dec = create_emb(es_vecs, data.y.vocab.itos)\n",
    "\n",
    "emb_enc.weight.size(), emb_dec.weight.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: the words in our vocabulary that are missing on the fasText's one will be set to random vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(emb_enc, path/'en_emb.pth')\n",
    "torch.save(emb_dec, path/'es_emb.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Load saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = torch.load(path/'en_emb.pth')\n",
    "emb_dec = torch.load(path/'es_emb.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Model\n",
    "\n",
    "The Model we will use is the classic Encoder-Decoder, using a GRU to encode the meaning of the sentence in the original language into a fixed-size vector that the decode will convert into the target language, hopefully conservint the meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" width=\"900\" autoplay loop>\n",
       "    <source src=\"https://jalammar.github.io/images/seq2seq_3.mp4\" type=\"video/mp4\">\n",
       "</video>\n",
       "<center>Video from Jay Alammar's <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">seq2seq post</a><center/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video alt=\"test\" width=\"900\" autoplay loop>\n",
    "    <source src=\"https://jalammar.github.io/images/seq2seq_3.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "<center>Video from Jay Alammar's <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">seq2seq post</a><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncDecRNN(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nl, self.nh, self.out_sl = nl, nh, out_sl\n",
    "        self.bos_idx, self.pad_idx = bos_idx, pad_idx\n",
    "        self.em_sz_enc = emb_enc.embedding_dim\n",
    "        self.em_sz_dec = emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(\n",
    "            self.em_sz_enc, nh, num_layers=nl, dropout=0.25, batch_first=True)\n",
    "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = emb_dec\n",
    "        self.gru_dec = nn.GRU(\n",
    "            self.em_sz_dec, self.em_sz_dec, num_layers=nl, dropout=0.1, batch_first=True)\n",
    "        \n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "        self.tf_weight = 0  # teacher forcing weight\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        _, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "        return h\n",
    "    \n",
    "    def decoder(self, dec_inp, h):\n",
    "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "        outp, h = self.gru_dec(emb, h)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return outp, h\n",
    "        \n",
    "    def forward(self, inp, targ=None):\n",
    "        bs, sl = inp.size()\n",
    "        h = self.encoder(bs, inp)\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            outp, h = self.decoder(dec_inp, h)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            res.append(outp)\n",
    "            if (dec_inp==self.pad_idx).all(): \n",
    "                break\n",
    "                \n",
    "            # Teacher forcing\n",
    "            if (targ is not None) and (random.random() < self.tf_weight):\n",
    "                if i>=targ.shape[1]: continue\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        return one_param(self).new_zeros(self.nl, bs, self.nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(data.valid_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncDecRNN(\n",
       "  (emb_enc): Embedding(5808, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15)\n",
       "  (gru_enc): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
       "  (out_enc): Linear(in_features=256, out_features=300, bias=False)\n",
       "  (emb_dec): Embedding(7016, 300, padding_idx=1)\n",
       "  (gru_dec): GRU(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (out): Linear(in_features=300, out_features=7016, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = EncDecRNN(emb_enc, emb_dec, 256, 20)\n",
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(LearnerCallback):\n",
    "    \"Callback used to redice tf_weight on each epoch\"\n",
    "    def __init__(self, learn, end_epoch):\n",
    "        super().__init__(learn)\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.learn.model.tf_weight = max(1 - epoch/self.end_epoch, 0)\n",
    "        \n",
    "class TF_metric(Callback):\n",
    "    \"Callback to print teacher forcing weight during training\"\n",
    "    def __init__(self, model):\n",
    "        self.name = 'tf_weight'\n",
    "        self.model = model\n",
    "        \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        return add_metrics(last_metrics, self.model.tf_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Metrics and loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 Cross-Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(out, targ, pad_idx=1):\n",
    "    bs, targ_len = targ.size()\n",
    "    _, out_len, vs = out.size()\n",
    "    if targ_len > out_len: \n",
    "        out  = F.pad(out, (0, 0, 0, targ_len - out_len, 0, 0), value=pad_idx)\n",
    "    if out_len > targ_len: \n",
    "        targ = F.pad(targ, (0, out_len - targ_len, 0, 0), value=pad_idx)\n",
    "    return CrossEntropyFlat()(out, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2 Token-level accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.3 BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): \n",
    "        self.ngram,self.max_n = ngram,max_n\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): \n",
    "            return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    \n",
    "    def __hash__(self): \n",
    "        return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))\n",
    "\n",
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]\n",
    "\n",
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams, targ_grams = get_grams(pred, n, max_n=max_n), get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt, targ_cnt = Counter(pred_grams), Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g, c in pred_cnt.items()]), len(pred_grams)\n",
    "\n",
    "class CorpusBLEU(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.name = 'bleu'\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.pred_len, self.targ_len, self.corrects, self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output.argmax(dim=-1)\n",
    "        for pred, targ in zip(last_output.cpu().numpy(), last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c, t = get_correct_ngrams(pred, targ, i + 1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return add_metrics(last_metrics, bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    data, rnn, loss_func=cross_entropy, \n",
    "    metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos)), TF_metric(rnn)], \n",
    "    callback_fns=partial(TeacherForcing, end_epoch=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>tf_weight</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.310207</td>\n",
       "      <td>3.215026</td>\n",
       "      <td>0.590341</td>\n",
       "      <td>0.420931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.147947</td>\n",
       "      <td>3.030729</td>\n",
       "      <td>0.544406</td>\n",
       "      <td>0.406101</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.914343</td>\n",
       "      <td>3.287255</td>\n",
       "      <td>0.512942</td>\n",
       "      <td>0.354443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.413641</td>\n",
       "      <td>3.029603</td>\n",
       "      <td>0.546262</td>\n",
       "      <td>0.378552</td>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('baseline');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: a note on bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Cualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the model on evaluation mode\n",
    "learn.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='48' class='' max='48', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48/48 00:07<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    \"returns predictions and non-reconstructed activations\"\n",
    "    ds = learn.data.train_ds\n",
    "    rxs, rys, rzs, xs, ys, zs = [],[],[],[],[],[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                rxs.append(ds.x.reconstruct(x))\n",
    "                rys.append(ds.y.reconstruct(y))\n",
    "                preds = z.argmax(1)\n",
    "                rzs.append(ds.y.reconstruct(preds))\n",
    "                for a,b in zip([xs,ys,zs],[x,y,z]): a.append(b)\n",
    "    return rxs,rys,rzs,xs,ys,zs\n",
    "\n",
    "rxs, rys, rzs, xs, ys, zs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 Nucleus\n",
    "\n",
    "We will analyze the output using the our basic prediction of the most likely word and nucleus wich will pick a word from a set of likely words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def select_nucleus(outp, p=0.5):\n",
    "    probs = F.softmax(outp,dim=-1)\n",
    "    idxs = torch.argsort(probs, descending=True)\n",
    "    res,cumsum = [],0.\n",
    "    for idx in idxs:\n",
    "        res.append(idx)\n",
    "        cumsum += probs[idx]\n",
    "        if cumsum>p: return idxs.new_tensor([choice(res)])\n",
    "\n",
    "def decode_with_nucleus(self, inp, targ=None):\n",
    "    inp = inp[None]\n",
    "    bs, sl = inp.size()\n",
    "    h = self.encoder(bs, inp)\n",
    "    dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "\n",
    "    res = []\n",
    "    for i in range(self.out_sl):\n",
    "        outp, h = self.decoder(dec_inp, h)\n",
    "        dec_inp = select_nucleus(outp[0], p=0.3)\n",
    "        \n",
    "        res.append(dec_inp)\n",
    "        if (dec_inp==self.pad_idx).all(): \n",
    "            break\n",
    "\n",
    "        # Teacher forcing\n",
    "        if (targ is not None) and (random.random() < self.tr_weight):\n",
    "            if i>=targ.shape[1]: continue\n",
    "            dec_inp = targ[:,i]\n",
    "    return torch.stack(res)\n",
    "\n",
    "def predict_with_nucleus(learn, x, y):\n",
    "    ds = learn.data.train_ds\n",
    "    with torch.no_grad():\n",
    "        out = decode_with_nucleus(learn.model, x)\n",
    "        rx = ds.x.reconstruct(x)\n",
    "        ry = ds.y.reconstruct(y)\n",
    "        rz = ds.y.reconstruct(out.squeeze())\n",
    "    return rx,ry,rz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj he will be xxunk in due time .\n",
      "xxbos xxmaj se se en en tiempo . .\n",
      "xxbos xxmaj se ha a de de . .\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos i ' ve been xxunk .\n",
      "xxbos xxmaj he estado xxunk . .\n",
      "xxbos xxmaj he estado de . .\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos xxmaj oh stop it !\n",
      "xxbos ¡ xxmaj oh !\n",
      "xxbos ¡ xxmaj ! !\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos i don ' t hold breath .\n",
      "xxbos xxmaj no me xxunk .\n",
      "xxbos xxmaj no entiendo un .\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos xxmaj xxunk the xxunk xxmaj xxunk .\n",
      "xxbos xxmaj xxunk xxunk xxunk xxunk xxunk\n",
      "xxbos xxmaj xxunk xxunk xxunk xxunk xxunk\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos xxmaj someone else killed xxmaj kim xxmaj xxunk .\n",
      "xxbos xxmaj alguien alguien a xxmaj xxmaj xxmaj .\n",
      "xxbos xxmaj alguien a xxmaj xxunk xxmaj xxmaj .\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos xxmaj denied each time .\n",
      "xxbos xxmaj se a tiempo .\n",
      "xxbos xxmaj se al . .\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos i ' m in love with her .\n",
      "xxbos xxmaj estoy voy con ella .\n",
      "xxbos xxmaj estoy en a su\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos ! let me in !\n",
      "xxbos ¡ xxmaj xxunk !\n",
      "xxbos ¡ xxmaj me ! !\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "xxbos xxmaj you have evidence ?\n",
      "xxbos ¿ xxmaj tienes ? ?\n",
      "xxbos ¿ xxmaj tienes ? ?\n",
      "~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    i = np.random.randint(0, len(inputs))\n",
    "    print(rxs[i])\n",
    "    print(rzs[i])\n",
    "    _, _, nucleus_prediction = predict_with_nucleus(learn, xs[i], ys[i])\n",
    "    print(nucleus_prediction)\n",
    "    print('~'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of different things can be tried to improve this baseline but we don't want to loose too much time on it, some ideas that could be incorporated here are:\n",
    "\n",
    "- better predictions with [beam search](https://en.wikipedia.org/wiki/Beam_search)\n",
    "- align batches in a way that allows us to keep h between them? similar to what is done in [notebook 6](https://github.com/fastai/course-nlp/blob/master/6-rnn-english-numbers.ipynb) of fast.ai's course\n",
    "- Handle UNK better using a sub-word tokenizer like [BPT](https://github.com/rsennrich/subword-nmt) or [SentencePiece](https://github.com/google/sentencepiece)\n",
    "- train with the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring alternatives\n",
    "\n",
    "Now that we have a basic understanding of the problem we will dive into more novel solutions. On this section is I'll enumerate different alternatives and pick one to try, I encourage you to choose a different one so that we can compare results later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenizer and embedding \n",
    "\n",
    "FastText was OK for our baseline but there are much better embedings that we can choose, here are the most important ones:\n",
    "\n",
    "- UMLFit\n",
    "- ELMO\n",
    "- BERT\n",
    "- *Other?* - NLP is in the middle of a revolution, keep an eye on the latest news.\n",
    "\n",
    "Training one of these more advanced models from scratch is quite lengthy and it might not be possible on the available hardware we have. As a reference, I trained UMLFit from scratch on the whole wikipedia in spanish on a 2080 Ti with 11GB and took ~25hrs ([notebook](./nn-spanish.ipynb)).\n",
    "\n",
    "For this reason I highly recommend using pre-trained models where possible (for english there are pre-trained weights available for all models but for spanish there might not be available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. UMLFit with transformers\n",
    "\n",
    "I will use the embeddings from [ULMFit](https://arxiv.org/pdf/1801.06146.pdf) because I have pretrained models for both languages. As for the model I'll replace our RNN-based encoder-decoder with a [transformer](https://arxiv.org/pdf/1706.03762.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 English embeddings\n",
    "\n",
    "We will start with ULMFit's pre-trained model for english and fin-tuned it on our subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.home()/'open_subtitles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javiber/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('subtitles.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(df, path=path, cols='en')\n",
    "            .split_by_rand_pct(0.1, seed=42)\n",
    "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()           \n",
    "           #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs, num_workers=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('lm_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path/'lm_en', bs=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='22962', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-05d54dad21bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/javiber-jarMRqt3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn_lm.fit_one_cycle(2, 1e-1, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(8, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.save(f'en_fine_tuned')\n",
    "learn_lm.save_encoder(f'en_fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Spanish embeddings\n",
    "\n",
    "We do the same for spanish, in this case the pre-trained spanish LM was trained by me on [this notebook](./nn-spanish.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm_es = (TextList.from_df(df, path=path, cols='es')\n",
    "            .split_by_rand_pct(0.1, seed=42)\n",
    "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()           \n",
    "           #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs, num_workers=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm_es = language_model_learner(data_lm_es, AWD_LSTM, pretrained_fnames=[f'es_wt', f'es_wt_vocab'], drop_mult=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
